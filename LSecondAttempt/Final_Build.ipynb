{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Imports\n",
    "\n",
    "- numpy will be handy for mathematical functions.\n",
    "- matplotlib will be used for the visualisation of the maze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Maze\n",
    "\n",
    "- Using matplotplib we use arrays filled with zeros (open space) and ones (walls) to build the maze structure. \n",
    "- In here, we also define the positions of the starting area, the end goal, and the sub goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialising the maze\n",
    "class Maze:\n",
    "    def __init__(self, maze, start_position, goal_position, sub_goal_position):\n",
    "        self.maze = maze\n",
    "        \n",
    "        self.maze_width = maze_struc.shape[1]           # rows of maze, also knows as x-azis. \n",
    "        self.maze_height = maze_struc.shape[0]          # columns of maze, also known as y-axis.\n",
    "\n",
    "        self.start_position = start_position            # start position - S.\n",
    "        self.goal_position = goal_position              # end goal position - E.\n",
    "        self.sub_goal_position = sub_goal_position      # sub goal position - G.\n",
    "\n",
    "    def show_maze(self):\n",
    "        plt.figure(figsize=(5,5))\n",
    "\n",
    "        plt.imshow(self.maze, cmap='Pastel1_r')\n",
    "\n",
    "        # Placements for the start, end, and sub goal positions.\n",
    "        plt.text(self.start_position[0], self.start_position[1], 'S', ha='center', va='center', color='green', fontsize=15)\n",
    "        plt.text(self.goal_position[0], self.goal_position[1], 'E', ha='center', va='center', color='red', fontsize=15)\n",
    "        plt.text(self.sub_goal_position[0], self.sub_goal_position[1], 'G', ha='center', va='center', color='blue', fontsize=15)\n",
    "\n",
    "        # Add grid lines between every wall/space.\n",
    "        plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "        plt.xticks(np.arange(0.5, self.maze.shape[1], 1))\n",
    "        plt.yticks(np.arange(0.5, self.maze.shape[0], 1))\n",
    "        plt.gca().set_xticks(np.arange(-0.5, self.maze.shape[1], 1), minor=True)\n",
    "        plt.gca().set_yticks(np.arange(-0.5, self.maze.shape[0], 1), minor=True)\n",
    "        plt.gca().grid(which='minor', color='grey', linestyle='-', linewidth=0.5)\n",
    "        plt.gca().tick_params(which='both', length=0)\n",
    "\n",
    "        plt.xlim(-0.45, self.maze.shape[1] - 0.5)\n",
    "        plt.ylim(self.maze.shape[0] - 0.6, -0.4)\n",
    "\n",
    "        # Hide the digits and labels from the plot visualistion. \n",
    "        plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        # Ensures the plot will visualise when running the code.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# The layout of the 10x10 maze:\n",
    "# 1 = wall.\n",
    "# 0 = open area.\n",
    "# (If wanted, we can later make another file where we can generate larger mazes like 100x100).\n",
    "maze_struc = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Places the start, end, and sub goal at the correct coordinates (rows, columns).\n",
    "maze = Maze(maze_struc, (1, 1), (7, 8), (3,5))\n",
    "\n",
    "# Actually visualises the plot with matplotlib.\n",
    "maze.show_maze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent\n",
    "\n",
    "This is where the logic of the agent come in:\n",
    "- The agent can move in four directions. These are up, down, left, and right. \n",
    "- The q learning formula and logic will be applied to it. The parameters the agent will go off are:\n",
    "    - the learning rate → decides how much new information overrides over information.\n",
    "    - the discount factor → decides if the agent will prefer better rewards later on, or smaller awards right away\n",
    "    - exploration rate → exploration vs. exploitation. This code works with a decay, over time it will proper exploitation over exploration in the maze.\n",
    "\n",
    "- The agent is based on this formula of Q-Learning:\n",
    "\n",
    "$$ Q(s, a) ← Q(s, a) + α [r + γ max(a') Q(s', a') - Q(s, a)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions the agent can take.\n",
    "moves = [\n",
    "   (-1, 0),         # Moving one step up.\n",
    "   (1, 0),          # Moving one step down.\n",
    "   (0, -1),         # Moving one step left.\n",
    "   (0, 1)           # Moving one step right.\n",
    "]\n",
    "\n",
    "# Initialise the Q-Learning agent \n",
    "class QLearningAgent:\n",
    "    def __init__(self, maze, learning_rate=0.1, discount_factor=0.9, exploration_start=1.0, exploration_end=0.01, num_episodes=100):\n",
    "        \n",
    "        # The table gets updated as new information is stored. 4 stands for the actions the agent can take. \n",
    "        self.q_table = np.zeros((maze.maze_height, maze.maze_width, 4)) \n",
    "         \n",
    "        self.learning_rate = learning_rate          \n",
    "        self.discount_factor = discount_factor      \n",
    "        self.exploration_start = exploration_start  \n",
    "        self.exploration_end = exploration_end\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    # Calculates the rate of exploration to exploitation over time -> start with a lot of exploration and eventually prefer exploitation.\n",
    "    def get_exploration_rate(self, current_episode):\n",
    "        exploration_rate = self.exploration_start * (self.exploration_end / self.exploration_start) ** (current_episode / self.num_episodes)\n",
    "        return exploration_rate\n",
    "    \n",
    "    # Chooses what movement action to make. \n",
    "    def get_action(self, state, current_episode):\n",
    "        exploration_rate = self.get_exploration_rate(current_episode)\n",
    "\n",
    "        # Select an action for the given state either randomly (exploration) or using the Q-table (exploitation).\n",
    "        if np.random.rand() < exploration_rate:\n",
    "            return np.random.randint(4) \n",
    "        else:\n",
    "            #Chooses the action with the highest Q-value for the given state.\n",
    "            return np.argmax(self.q_table[state]) \n",
    "        \n",
    "    # Updates the Q-values in the Q-table based on its actions and states.\n",
    "    def update_q_table(self, state, action, next_state, reward):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "\n",
    "        current_q_value = self.q_table[state][action]\n",
    "\n",
    "        # Formula to update the Q-value based on the theory of the Q-Learning algorithm.\n",
    "        new_q_value = current_q_value + self.learning_rate * (reward + self.discount_factor * self.q_table[next_state][best_next_action] - current_q_value)\n",
    "\n",
    "        # Apply new Q-value for current action and state. \n",
    "        self.q_table[state][action] = new_q_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Agent in Maze\n",
    "\n",
    "This cell will show the behaviour of the agent in a single episode and before it is trained with the Q-Learning algorithm.\n",
    "\n",
    "- It DOES define the logic on the agent inside of the maze. In other words, giving the agent rewards and penalities for hitting walls and reaching the goal, respectively.\n",
    "- So, it keeps track of the total reward.\n",
    "- It also tracks the total steps the agent took.\n",
    "- It also updates the Q-values as necessary.\n",
    "\n",
    "Below, we first initialise the rewards or penalties the agent will receive based on its behaviour. Change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reward = 100\n",
    "sub_goal_reward = 50\n",
    "\n",
    "wall_penalty = -10\n",
    "step_penalty = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_episode(agent, maze, current_episode, train=True):\n",
    "\n",
    "    current_state = maze.start_position     # Agent starts at start position.\n",
    "    path = [current_state]                  # Tracks the agent's current position.\n",
    "\n",
    "    goal_reached = False                    # Tracks if the agent reached the goal.\n",
    "    sub_reached = False                     # Tracks if the agent reached the sub goal.\n",
    "\n",
    "    episode_reward = 0                      # Tracks the agent's total award at the end of the episode.\n",
    "    episode_step = 0                        # Tracks the agent's total steots at the end of the episode.\n",
    "    \n",
    "\n",
    "    while not goal_reached:\n",
    "\n",
    "        # Decides the next agent's next action based on the Q-Table.\n",
    "        action = agent.get_action(current_state, current_episode)\n",
    "        next_state = (current_state[0] + moves[action][0], current_state[1] + moves[action][1])\n",
    "\n",
    "        # Give a penalty is a wall is hit.\n",
    "        if (next_state[0] < 0 or next_state[0] >= maze.maze_height or \n",
    "            next_state[1] < 0 or next_state[1] >= maze.maze_width or \n",
    "            maze.maze[next_state[1]][next_state[0]]) == 1:\n",
    "            reward = wall_penalty\n",
    "            next_state = current_state\n",
    "\n",
    "        # Give a single-time reward is the sub goal is reached.\n",
    "        elif next_state == (maze.sub_goal_position) and not sub_reached:\n",
    "            path.append(current_state)\n",
    "            reward = sub_goal_reward\n",
    "            sub_reached = True\n",
    "\n",
    "        # Mark that agent has reached the end and give reward.\n",
    "        elif next_state == (maze.goal_position):\n",
    "            path.append(current_state)\n",
    "            reward = goal_reward\n",
    "            goal_reached = True\n",
    "\n",
    "        # Give a penalty every time the agent takes a step without it being at the final goal position.\n",
    "        else:\n",
    "            path.append(current_state)\n",
    "            reward = step_penalty\n",
    "\n",
    "        # Keeps track of the total steps and reward.\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "\n",
    "        # Updates Q-table is set to True.\n",
    "        if train == True:\n",
    "            agent.update_q_table(current_state, action, next_state, reward)\n",
    "\n",
    "        # Looping through this will cause agent to take a next action/step.\n",
    "        current_state = next_state\n",
    "\n",
    "    # Shows total reward, steps and the path it took.\n",
    "    return episode_reward, episode_step, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Agent Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Path:\n",
      "(1, 1)-> (1, 1)-> (1, 2)-> (1, 3)-> (1, 2)-> (1, 3)-> (2, 3)-> (3, 3)-> (2, 3)-> (1, 3)-> (2, 3)-> (1, 3)-> (1, 2)-> (1, 3)-> (1, 2)-> (1, 3)-> (2, 3)-> (1, 3)-> (1, 2)-> (1, 1)-> (1, 2)-> (1, 1)-> (1, 2)-> (1, 1)-> (1, 2)-> (1, 3)-> (2, 3)-> (3, 3)-> (3, 4)-> (3, 3)-> (3, 2)-> (3, 1)-> (3, 2)-> (3, 1)-> (3, 2)-> (3, 3)-> (3, 4)-> (3, 5)-> (3, 6)-> (3, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (3, 5)-> (3, 6)-> (3, 5)-> (3, 4)-> (3, 5)-> (3, 4)-> (3, 3)-> (3, 4)-> (3, 5)-> (3, 4)-> (3, 5)-> (3, 6)-> (3, 5)-> (3, 6)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 4)-> (3, 5)-> (3, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (3, 6)-> (3, 7)-> (3, 6)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 6)-> (3, 7)-> (3, 6)-> (3, 7)-> (3, 8)-> (3, 7)-> (3, 6)-> (3, 5)-> (3, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (3, 6)-> (3, 7)-> (3, 8)-> (2, 8)-> (3, 8)-> (2, 8)-> (3, 8)-> (4, 8)-> (3, 8)-> (2, 8)-> (3, 8)-> (3, 7)-> (3, 6)-> (3, 7)-> (3, 8)-> (3, 7)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (3, 7)-> (3, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (3, 6)-> (3, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (3, 5)-> (4, 5)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (1, 6)-> (1, 5)-> (1, 6)-> (2, 6)-> (3, 6)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 4)-> (3, 3)-> (3, 2)-> (3, 3)-> (3, 4)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 6)-> (3, 5)-> (3, 6)-> (2, 6)-> (3, 6)-> (3, 5)-> (3, 6)-> (3, 5)-> (3, 4)-> (3, 3)-> (3, 4)-> (3, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (6, 5)-> (5, 5)-> (4, 5)-> (3, 5)-> (3, 6)-> (3, 7)-> (3, 6)-> (3, 5)-> (3, 4)-> (3, 3)-> (3, 4)-> (3, 3)-> (3, 2)-> (3, 3)-> (2, 3)-> (1, 3)-> (1, 2)-> (1, 1)-> (1, 2)-> (1, 1)-> (1, 2)-> (1, 3)-> (2, 3)-> (3, 3)-> (2, 3)-> (1, 3)-> (2, 3)-> (3, 3)-> (3, 4)-> (3, 5)-> (3, 6)-> (2, 6)-> (3, 6)-> (2, 6)-> (3, 6)-> (3, 5)-> (4, 5)-> (3, 5)-> (3, 4)-> (3, 5)-> (4, 5)-> (5, 5)-> (6, 5)-> (6, 6)-> (7, 6)-> (8, 6)-> (8, 5)-> (8, 6)-> (7, 6)-> (8, 6)-> (7, 6)-> (6, 6)-> (7, 6)-> (6, 6)-> (6, 5)-> (5, 5)-> (6, 5)-> (5, 5)-> (6, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (4, 5)-> (5, 5)-> (6, 5)-> (6, 6)-> (7, 6)-> (8, 6)-> (8, 5)-> (8, 4)-> (8, 5)-> (8, 6)-> (8, 7)-> (8, 8)-> (8, 7)-> (8, 8)-> (8, 7)-> (8, 8)-> End Reached.\n",
      "Total steps: 613\n",
      "Total reward: -3125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(613, -3125)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_agent(agent, maze, num_episodes=1):\n",
    "  \n",
    "    episode_reward, episode_step, path = finish_episode(agent, maze, num_episodes, train=False)\n",
    "\n",
    "    print(\"Final Path:\")\n",
    "    for row, col in path:\n",
    "        print(f\"({row}, {col})-> \", end='')\n",
    "    print(\"End Reached.\")\n",
    "\n",
    "    print(\"Total steps:\", episode_step)\n",
    "    print(\"Total reward:\", episode_reward)\n",
    "\n",
    "    # Visualise the maze like before again.\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(maze.maze, cmap='Pastel1_r')\n",
    "\n",
    "    plt.text(maze.start_position[0], maze.start_position[1], 'S', ha='center', va='center', color='green', fontsize=15)\n",
    "    plt.text(maze.goal_position[0], maze.goal_position[1], 'E', ha='center', va='center', color='red', fontsize=15)\n",
    "    plt.text(maze.sub_goal_position[0], maze.sub_goal_position[1], 'G', ha='center', va='center', color='blue', fontsize=15)\n",
    "\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.xticks(np.arange(0.5, maze.maze.shape[1], 1))\n",
    "    plt.yticks(np.arange(0.5, maze.maze.shape[0], 1))\n",
    "    plt.gca().set_xticks(np.arange(-0.5, maze.maze.shape[1], 1), minor=True)\n",
    "    plt.gca().set_yticks(np.arange(-0.5, maze.maze.shape[0], 1), minor=True)\n",
    "    plt.gca().grid(which='minor', color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.gca().tick_params(which='both', length=0)\n",
    "\n",
    "    plt.xlim(-0.45, maze.maze.shape[1] - 0.5)\n",
    "    plt.ylim(maze.maze.shape[0] - 0.6, -0.4)\n",
    "\n",
    "    # Additionally show the path the agent took.\n",
    "    for position in path:\n",
    "        plt.text(position[0], position[1], \"●\", va='center', color='pink', fontsize=10)\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show(block=True) \n",
    "\n",
    "    return episode_step, episode_reward\n",
    "\n",
    "agent = QLearningAgent(maze)\n",
    "test_agent(agent, maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
